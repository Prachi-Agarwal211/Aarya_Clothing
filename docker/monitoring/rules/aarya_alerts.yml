# Prometheus Alert Rules for Aarya Clothing
# Group: aarya_alerts

groups:
  - name: aarya_service_health
    rules:
      # Service Down Alert
      - alert: ServiceDown
        expr: up{job!~"prometheus|docker-daemon|nginx"} == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "{{ $labels.service }} is down"
          description: "Service {{ $labels.service }} has been down for more than 1 minute"
          runbook_url: "https://wiki.example.com/runbooks/service-down"

      # High Error Rate
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High error rate on {{ $labels.service }}"
          description: "Error rate is {{ $value | humanizePercentage }} on {{ $labels.service }} for {{ $labels.path }}"
          runbook_url: "https://wiki.example.com/runbooks/high-error-rate"

      - alert: CriticalErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.20
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "CRITICAL error rate on {{ $labels.service }}"
          description: "Error rate is {{ $value | humanizePercentage }} on {{ $labels.service }}"

      # High Latency
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High latency on {{ $labels.service }}"
          description: "95th percentile latency is {{ $value | humanizeDuration }}"

      - alert: CriticalLatency
        expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 5
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "CRITICAL latency on {{ $labels.service }}"
          description: "99th percentile latency is {{ $value | humanizeDuration }}"

  - name: aarya_database
    rules:
      # PostgreSQL Connection Pool Exhaustion
      - alert: PostgreSQLConnectionPoolExhausted
        expr: pg_stat_activity_count / pg_settings_max_connections > 0.85
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "PostgreSQL connection pool near capacity"
          description: "Connections at {{ $value | humanizePercentage }} of max"
          runbook_url: "https://wiki.example.com/runbooks/postgresql-connections"

      - alert: PostgreSQLConnectionPoolCritical
        expr: pg_stat_activity_count / pg_settings_max_connections > 0.95
        for: 1m
        labels:
          severity: critical
          team: database
        annotations:
          summary: "PostgreSQL connection pool CRITICAL"
          description: "Connections at {{ $value | humanizePercentage }} of max"

      # PostgreSQL Long Running Queries
      - alert: PostgreSQLLongRunningQueries
        expr: pg_stat_activity_max_seconds > 300
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "Long running queries detected"
          description: "Query running for {{ $value | humanizeDuration }}"
          runbook_url: "https://wiki.example.com/runbooks/postgresql-long-queries"

      # PostgreSQL Replication Lag (if using replica)
      - alert: PostgreSQLReplicationLag
        expr: pg_replication_lag_seconds > 30
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "PostgreSQL replication lag"
          description: "Replica is {{ $value | humanizeDuration }} behind primary"

  - name: aarya_redis
    rules:
      # Redis Memory High
      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.80
        for: 5m
        labels:
          severity: warning
          team: cache
        annotations:
          summary: "Redis memory usage high"
          description: "Memory at {{ $value | humanizePercentage }} of max"
          runbook_url: "https://wiki.example.com/runbooks/redis-memory"

      - alert: RedisMemoryCritical
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.90
        for: 2m
        labels:
          severity: critical
          team: cache
        annotations:
          summary: "Redis memory CRITICAL"
          description: "Memory at {{ $value | humanizePercentage }} of max"

      # Redis Connection Issues
      - alert: RedisConnectionIssues
        expr: rate(redis_connections_received_errors_total[5m]) > 0
        for: 5m
        labels:
          severity: warning
          team: cache
        annotations:
          summary: "Redis connection errors detected"
          description: "{{ $value }} connection errors in the last 5 minutes"

      # Redis Key Evictions
      - alert: RedisKeyEvictions
        expr: rate(redis_keyspace_evictions_total[1m]) > 100
        for: 5m
        labels:
          severity: warning
          team: cache
        annotations:
          summary: "Redis key evictions high"
          description: "{{ $value }} keys evicted per second"

  - name: aarya_elasticsearch
    rules:
      # Elasticsearch Cluster Health
      - alert: ElasticsearchClusterHealthRed
        expr: elasticsearch_cluster_health_status == 2
        for: 1m
        labels:
          severity: critical
          team: search
        annotations:
          summary: "Elasticsearch cluster health RED"
          description: "Cluster health is RED - some shards unavailable"
          runbook_url: "https://wiki.example.com/runbooks/elasticsearch-red"

      - alert: ElasticsearchClusterHealthYellow
        expr: elasticsearch_cluster_health_status == 1
        for: 5m
        labels:
          severity: warning
          team: search
        annotations:
          summary: "Elasticsearch cluster health YELLOW"
          description: "Cluster health is YELLOW - some replicas not allocated"

      # Elasticsearch High JVM Heap
      - alert: ElasticsearchJVMHeapHigh
        expr: elasticsearch_jvm_memory_heap_used_percent > 80
        for: 5m
        labels:
          severity: warning
          team: search
        annotations:
          summary: "Elasticsearch JVM heap high"
          description: "JVM heap at {{ $value | humanizePercentage }}"

  - name: aarya_infrastructure
    rules:
      # High CPU Usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | humanizePercentage }}"

      - alert: CriticalCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
        for: 2m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "CRITICAL CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | humanizePercentage }}"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanizePercentage }}"

      - alert: CriticalMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
        for: 2m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "CRITICAL memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanizePercentage }}"

      # Disk Space Low
      - alert: DiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100 > 80
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Disk space low on {{ $labels.instance }}"
          description: "Disk usage is {{ $value | humanizePercentage }} on {{ $labels.mountpoint }}"

      - alert: DiskSpaceCritical
        expr: (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100 > 90
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Disk space CRITICAL on {{ $labels.instance }}"
          description: "Disk usage is {{ $value | humanizePercentage }} on {{ $labels.mountpoint }}"

      # Load Average High
      - alert: LoadAverageHigh
        expr: node_load1 / count(node_cpu_seconds_total{mode="idle"}) > 1.5
        for: 15m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High load average on {{ $labels.instance }}"
          description: "Load average is {{ $value }}, which is above CPU core count"

  - name: aarya_event_stream
    rules:
      # Redis Stream Consumer Lag
      - alert: StreamConsumerLagHigh
        expr: stream_consumer_lag > 10000
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Consumer lag on {{ $labels.stream }} exceeds threshold"
          description: "Lag is {{ $value }} messages behind"

      # Event Processing Errors
      - alert: EventProcessingErrorsHigh
        expr: rate(event_processing_errors_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High event processing error rate"
          description: "{{ $value }} errors per second"

  - name: aarya_business_metrics
    rules:
      # Low Order Rate (business hours)
      - alert: LowOrderRate
        expr: rate(orders_created_total[1h]) < 0.5
        for: 2h
        labels:
          severity: warning
          team: business
        annotations:
          summary: "Unusually low order rate"
          description: "Order creation rate is {{ $value }} orders/hour"

      # High Cart Abandonment Rate
      - alert: HighCartAbandonment
        expr: rate(carts_abandoned_total[1h]) / rate(carts_created_total[1h]) > 0.8
        for: 1h
        labels:
          severity: warning
          team: business
        annotations:
          summary: "High cart abandonment rate"
          description: "{{ $value | humanizePercentage }} of carts are being abandoned"
